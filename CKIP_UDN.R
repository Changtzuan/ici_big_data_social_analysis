library(reticulate)
library(dplyr)
library(readr)
library(stringr)
library(tidyr)
library(progress)

# è¨­å®š Python ç’°å¢ƒ
use_python("C:/Users/user/ckip_env/Scripts/python.exe", required = TRUE)

# åŒ¯å…¥ CKIPTagger
ckiptagger <- import("ckiptagger")
ws <- ckiptagger$WS("./data", disable_cuda = FALSE)
pos <- ckiptagger$POS("./data", disable_cuda = FALSE)
ner <- ckiptagger$NER("./data", disable_cuda = FALSE)

# è¨­å®šè³‡æ–™å¤¾è·¯å¾‘
input_folder <- "D:/CJ/UDNdata/trump_articles/"
df <- read_csv("D:/CJ/UDNdata/udn_articles.csv")
output_tokenpos_csv <- "UDNdata/udn_articles_POS.csv"
output_ner_csv <- "UDNdata/udn_articles_NER.csv"
output_txt_folder <- "UDNdata/trump_articles_POS_TXT"
dir.create(output_txt_folder, showWarnings = FALSE)

# é å‚™å…©å€‹ç©ºæ¸…å–®
all_tokenpos <- list()  # å­˜ (è©, è©æ€§, æ¬¡æ•¸)
all_ner <- list()       # å­˜ (å¯¦é«”, é¡å‹)

# å»ºç«‹é€²åº¦æ¢
pb <- progress_bar$new(
  total = nrow(df),
  format = "  è™•ç†ä¸­ [:bar] :current/:total (:percent) in :elapsed"
)

# Process each file
for (i in seq_len(nrow(df))) {
  tryCatch({
    
    id <- df$UUID
    file_path <- paste0(input_folder, paste0(id, ".txt"))
    
    if (file.exists(file_path)) {
      text <- readLines(file_path, warn = FALSE)
      text <- paste(text, collapse = " ")
      
      # Select the text after "æ­£æ–‡:"
      text <- str_extract(text, "(?<=æ­£æ–‡:).*")
      
      # Skip if no text was extracted
      if (is.na(text) || text == "") {
        warning(paste0("No text found after 'æ­£æ–‡:' in file: ", file_path))
        next
      }
      
      # WS + POS + NER
      ws_result <- ws(list(text))
      pos_result <- pos(ws_result)
      ner_result <- ner(ws_result, pos_result)

      tokens <- ws_result[[1]]
      pos_tags <- pos_result[[1]]

      ## ====== (1) è™•ç† WS + POS ======

      # å°‡è©å’Œè©æ€§çµ„åˆæˆæ‰€éœ€æ ¼å¼
      tokenpos_text <- paste0(tokens, "(", pos_tags, ")", collapse = "ã€€")
      
      # å°‡çµæœå¯«å…¥ TXT æ–‡ä»¶
      output_txt_path <- file.path(output_txt_folder, paste0(id, ".txt"))
      writeLines(tokenpos_text, output_txt_path)
      
      tokenpos_df <- tibble(
       ID = id,
       word = tokens,
       pos = pos_tags
      ) %>%
       count(ID, word, pos, name = "count")  # Count occurrences of each (word/POS)

      all_tokenpos[[i]] <- tokenpos_df

      ## ====== (2) ç›´æ¥å­˜å„² NER çµæœ ======
      if (!is.null(ner_result) && length(ner_result) > 0) {
        # å°‡ NER çµæœè½‰æ›ç‚ºå­—ç¬¦ä¸²ä¸¦å­˜å„²
        # ä½¿ç”¨ toString æˆ– as.character å­˜å„²åŸå§‹çµæœ
        ner_string <- toString(ner_result[[1]])
        all_ner[[i]] <- tibble(ID = id, ner_result = ner_string)

        # å°å‡º NER æ•¸é‡è³‡è¨Š
        ner_count <- ifelse(is.character(ner_result[[1]]),
                            str_count(ner_result[[1]], "\\("),
                            length(ner_result[[1]]))
        # print(paste0("ID: ", id, " NER: ", ner_count, " å€‹å¯¦é«”"))
      } else {
        all_ner[[i]] <- tibble(ID = id, ner_result = NA_character_)
      }
    } else {
      warning(paste0("æ‰¾ä¸åˆ°æª”æ¡ˆï¼š", file_path))
    }
  }, error = function(e) {
    warning(paste0("è™•ç† ID ", df$UUID[i], " æ™‚ç™¼ç”ŸéŒ¯èª¤: ", e$message))
  })
  
  # æ›´æ–°é€²åº¦æ¢
  pb$tick()
}

# åˆä½µæ‰€æœ‰æ–°èçµæœ
all_tokenpos1 <- Filter(function(df) nrow(df) > 0, all_tokenpos)
final_tokenpos <- bind_rows(all_tokenpos1)
final_ner <- bind_rows(all_ner)

# è¼¸å‡ºå…©å€‹è¡¨æ ¼
write_csv(final_tokenpos, output_tokenpos_csv)
write_csv(final_ner, output_ner_csv)

cat("\nğŸ‰ (è©+è©æ€§) è¡¨æ ¼ã€NER è¡¨æ ¼éƒ½å®Œæˆï¼å·²è¼¸å‡ºå…©å€‹æ–°CSVï¼\n")
